import pandas as pd
import numpy as np
import joblib
import scapy.all as scapy
import gradio as gr
import os
import threading
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

# Function to train the model
def train_model():
    # Load the dataset
    data = pd.read_csv(r'F:\Cyber_Ai-main\Malware detection\Malware dataset.csv')

    # Encode all object-type columns to numeric values
    label_encoders = {}
    for column in data.select_dtypes(include=['object']).columns:
        le = LabelEncoder()
        data[column] = le.fit_transform(data[column])
        label_encoders[column] = le

    # Define features and labels
    X = data.drop(columns=['classification'])  # Exclude the label column
    y = data['classification']  # Use the label column

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # Hyperparameter tuning with a reduced parameter grid and fewer cross-validation folds
    param_grid = {
        'n_estimators': [50, 100],
        'max_depth': [None, 10],
        'min_samples_split': [2, 5],
    }

    grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3)
    grid_search.fit(X_train, y_train)

    # Best model
    model = grid_search.best_estimator_

    # Save the trained model and feature names
    joblib.dump(model, 'malware_detection_model.pkl')
    joblib.dump(X.columns.tolist(), 'feature_names.pkl')

    print("Model trained and saved successfully.")

# Function to calculate entropy
def calculate_entropy(content):
    if len(content) == 0:
        return 0

    if isinstance(content, str):
        content = content.encode('utf-8')

    byte_counts = np.bincount(np.frombuffer(content, dtype=np.uint8))
    entropy = -sum((count / len(content)) * np.log2(count / len(content)) for count in byte_counts if count > 0)

    return entropy

# Function to extract features from uploaded files
def extract_features(file_path):
    features = []

    file_size = os.path.getsize(file_path)
    features.append(file_size)

    with open(file_path, 'rb') as f:
        content = f.read()
        features.append(len(content))
        entropy = calculate_entropy(content)
        features.append(entropy)

    # Pad features to match the expected number
    while len(features) < 34:
        features.append(0)  # Example of padding with zeros

    return np.array(features)

# Function to scan a directory for files and classify them
def scan_directory(directory):
    malware_files = []
    clean_files = []

    for root, dirs, files in os.walk(directory):
        for file in files:
            file_path = os.path.join(root, file)
            try:
                features = extract_features(file_path)

                # Load feature names
                feature_names = joblib.load('feature_names.pkl')

                # Create DataFrame from features with the correct column names
                features_df = pd.DataFrame([features], columns=feature_names)

                # Load the trained model
                model = joblib.load('malware_detection_model.pkl')

                # Predict using the loaded model
                prediction = model.predict(features_df)

                # Classify files
                if prediction[0] == 1:
                    malware_files.append(file_path)
                else:
                    clean_files.append(file_path)
            except Exception as e:
                print(f"Error processing file {file_path}: {e}")

    return malware_files, clean_files

# Gradio interface function for file upload
def predict_malware(file):
    if file is None:
        return "No file uploaded."

    features = extract_features(file.name)

    # Load feature names
    feature_names = joblib.load('feature_names.pkl')

    # Create DataFrame from features with the correct column names
    features_df = pd.DataFrame([features], columns=feature_names)

    # Load the trained model
    model = joblib.load('malware_detection_model.pkl')

    # Predict using the loaded model
    prediction = model.predict(features_df)

    # Return the result
    return "Malware detected" if prediction[0] == 1 else "File is clean"

# Gradio interface for scanning a directory
def scan_now(directory):
    malware_files, clean_files = scan_directory(directory)

    return (f"Malware Files: {len(malware_files)}\n" + "\n".join(malware_files) + "\n\n" +
            f"Clean Files: {len(clean_files)}\n" + "\n".join(clean_files))

# Function to extract features from packets
def extract_packet_features(packet):
    features = []

    features.append(len(packet))

    if packet.haslayer(scapy.IP):
        features.append(packet[scapy.IP].src)  # Source IP
        features.append(packet[scapy.IP].dst)  # Destination IP
    else:
        features.append(0)  # Padding if no IP layer
        features.append(0)  # Padding if no IP layer

    # Load feature names
    feature_names = joblib.load('feature_names.pkl')

    # Pad features to match the expected number
    while len(features) < len(feature_names):
        features.append(0)  # Padding with zeros

    return np.array(features)

# Callback function to process packets
def process_packet(packet):
    # Load feature names and model
    feature_names = joblib.load('feature_names.pkl')
    model = joblib.load('malware_detection_model.pkl')

    features = extract_packet_features(packet)

    # Create DataFrame for prediction
    features_df = pd.DataFrame([features], columns=feature_names)

    # Predict using the loaded model
    prediction = model.predict(features_df)

    # Log the result
    if prediction[0] == 1:
        print(f"Malware detected in packet from {packet[scapy.IP].src} to {packet[scapy.IP].dst}")

# Function to start sniffing packets
def start_sniffing():
    print("Starting packet sniffing...")
    scapy.sniff(prn=process_packet, store=0)

# Main function to run everything
if __name__ == "__main__":
    train_model()  # Train the model first

    # Start sniffing packets in a separate thread
    sniffing_thread = threading.Thread(target=start_sniffing)
    sniffing_thread.start()

    # Create Gradio Interfaces
    file_interface = gr.Interface(
        fn=predict_malware,
        inputs=gr.File(label="Upload a file for malware detection"),
        outputs=gr.Text(),
        title="Malware Detection Interface",
        description="Upload a file to check if it's malware."
    )

    scan_interface = gr.Interface(
        fn=scan_now,
        inputs=gr.Textbox(label="Enter directory path to scan"),
        outputs=gr.Text(),
        title="Device Scan",
        description="Enter a directory path to scan for malware."
    )

    # Launch the interfaces
    demo = gr.TabbedInterface([file_interface, scan_interface], ["File Upload", "Directory Scan"])
    demo.launch(share=True)  # Set share=True to create a public link
